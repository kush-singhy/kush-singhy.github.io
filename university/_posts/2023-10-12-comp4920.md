---
layout: post
title:  "COMP4920 Notes"
date:   2023-10-12 18:06:02 +1000
category: university
---

## Management and Ethics

## Week 1

- *Statement* and *Proposition* will be used interchangeably
- Truth-apt - statements that make a declaration about the way things are or are not. Not necessarily true, but something that could be true.
    - Requests & commands are NOT truth-apt
    - “This sentence is false” - not sure if this statement is truth-apt or not (yes for the sake of this course)
- Are moral statements truth-apt?
    - “Burning kittens is wrong”
- Meta-ethics:
    - Cognitivists - those who say moral judgements are truth-apt
    - Non-cognitivists - those who say moral judgements are not truth-apt

| Cognitivism | Non-Cognitivism |
| --- | --- |
| Divine Command Theory - The truth maker for moral judgements is God’s Will | Expressivism - We are expressing our internal subjective states without making a truth-apt statement. When we make ‘moral judgements’ we are merely portraying linguistic behaviour that gives away our internal subjective state.   |
| Objective Moral Realism - The truth makers for moral judgements are part of the natural world (axioms) | Motivism |
| Cultural Relativism - The truth makers for moral judgements are the majority opinions of the culture within which the judgement is being made | Preferentialism |
| Subjectivism - The truth maker is the individuals internal subjective state. They are making a truth-apt statement about the state they are/will be in.  |  |
| Error Theory - The truth makers for moral judgements are moral properties that exist in the world. However, moral properties do not exist, therefore all moral judgements are false.  |  |
| Fictionalist - A type of error theorist that believes we should still make moral judgements. Moral judgements are fictional but useful.  |  |
| Nihilism - A type of error theorist that believes we should stop making moral judgements.  |  |

### Reading Summary

**Metaethics** dives into the underpinnings and foundational concepts of moral thought, dialogue, and practice. It grapples with questions such as the nature of morality, its origin, and its relation to human psychology, motivations, and behavior.

1. **General Observations**: Metaethics strives to understand the shared assumptions and commitments in moral debates. It delves into the core tenets and philosophies behind moral decisions, often abstracting from specific moral judgments to study overarching moral ideologies.
2. **The Euthyphro Problem**: This classic philosophical dilemma questions whether moral value is derived from divine command or if it exists independently. It explores the challenges of associating moral principles solely with God's commands.
3. **Is/Ought and the Open Question Argument**: Highlighted by David Hume, it posits that evaluative claims (‘ought’ claims) cannot be solely derived from factual claims (‘is’ claims). G.E. Moore furthered this argument by challenging naturalistic views of morality, suggesting that moral judgments aren't merely attributions of natural properties.
4. **Morals, Motives, and Reasons**: Morality is inherently linked to action. When one makes a moral judgment, it's believed to naturally provide a reason or motivation for action. This relationship between moral judgments, motivations, and reasons for action is central to understanding the value and relevance of moral considerations.
5. **Freedom and Responsibility**: The concept of free will is crucial when discussing moral responsibility. The questions here revolve around whether moral responsibility presupposes free will and, if so, what constitutes free will. The debate spans arguments suggesting that free will is an illusion to those believing it's determined by reason or other factors.

In essence, metaethics scrutinizes the foundations of moral beliefs, their origins, and their implications on human behavior and thought. The field raises intricate questions about the nature of good and evil, the role of divinity in moral judgments, and the intertwining of moral decisions with motivations and free will.

## Week 2

- Normative Ethics - prescribes norms to how we should or should not act
- Argument - reasons designed to convince somebody of the truth about some declarative statement
- Consequentialist - morality based on the consequences of actions
- Utilitarianism - type of consequentialist
    - Utility - overall happiness
    - Moral judgements are falsifiable like scientific claims.
    - Act utilitarianism - determining utility before committing an act
    - Rule utilitarianism - an action is right as it conforms to a rule that leads to the greatest good
    - Utilitarianism is epistemic
- Naturalism - anything that happens, happens in the natural world
- Utilitarianism is compatible with Naturalism.

- Deontological (Kantian) Ethics
- The Universal law formulation - an algorithm such that if we run it in our minds we will always do the right thing.
- Categorial Imperative -  act only in accordance with that maxim that you could at the same time will to become a universal law
    - Meaning: follow a certain moral rule only if you would be happy with it being a universal law. I.e. you would be happy with it governing every person in the world.

## Week 3

- The neutrality of technology:
    - “Technology is neither good nor bod; nor is it neutral”
    - The consequences of technology depends on context and circumstances, and this is an argument for it not being neutral
- Embedding the following in the technology we develop:
    - Values
    - Principles - how we display our values
    - Purpose
    - Responsibilities - expectations on how we act
    - Practices - the things we do to accomplish our responsibilities
- Ethical principles vs Law?
    - An action being legal does not necessitate that it is ethical
    - Ethical principles are broader and can be used to interpret, criticise and evaluate existing laws.
- Code of Ethics: A set of ideals, virtues & guiding principles
- Code of Conduct: More specific set of guidelines for a profession

- Ethics in computing:
    - *“The Code is designed to inspire and guide the ethical conduct of all computing professionals, including current and aspiring practitioners, instructors, students, influencers, and anyone who uses computing technology in an impactful way. The Code includes principles formulated as statements of responsibility, based on the understanding that the public good is always the primary consideration.”*
    - **ACM Code of Ethics and Professional Computing**: All people are stakeholders in computing, honesty, privacy, confidentiality, respect

**AI Ethics**

- There has been a large spike in AI usage
    - Main reasons: decreased costs, increased revenue
- The term Artificial Intelligence was coined in 1956
- Data is the core of AI:
    - This data has to be collected and used, which means issues related to AI are closely intertwined with those that relate to privacy and data.
- The three subfields of ethics:
    - Meta-ethics
    - Normative ethics
    - **Applied ethics** ← AI Ethics fits here
- AI ethics has rapidly converged on a set of five principles:
    - non-maleficence
    - responsibility or accountability
    - transparency and explainability
    - justice and fairness
    - respect for human rights such as privacy and security
- Beneficence vs Non-maleficence (Do good vs Do no harm)
    - most ethical frameworks rely on non-maleficence rather than beneficence. It is easier to define ‘doing no harm’ than to define ‘doing good’.
- **Automated Decision Making System (ADMS)** - An ADMS describes a computerised process that either assists or replaces the judgement of human decision-makers.
- Level of automation vs Human control:
    - These are not mutually exclusive
    
    ![Untitled]({{ "/images/comp4920images/Untitled.png" | absolute_url }})
    
- AI Value Alignment:
    - AI should be designed to align with the norms and values of your user group

## Week 4

- Examples of Ethical Dilemmas:
    - Whistleblowing
    - Animal testing for scientific research
- Examples of ethical dilemmas in AI/ADMS:
    - Job displacement
    - Autonomous vehicles in an accident
    - Biased systems
    - Deploying less reliable alpha prototypes to improve the systems - tech companies that want to be first to market releasing unreliable prototypes that could potentially cause harm
- AI value alignment is needed because AI has multiple stakeholders each of which have multiple values.
- Identifying users and stakeholders
    - A user: anybody that will be gaining value from your product, by completing a task within your product
- User research methods
    
    ![Untitled]({{ "/images/comp4920images/Untitled%201.png" | absolute_url }})
    
    - Attitudinal vs Behavioural
    - Qualitative vs Quantitative
    - Context of Use
- **Personas** - a tool to help define user groups. They are models of typical users.

**Value Sensitive Design (VSD)**

- VSD - an approach that accounts for human values in the technical design and engineering process
    - Begins with the identification of stakeholders
    - Surfacing of their values through conceptual and empirical investigations
- Trade-offs:
    - Privacy vs Utility
    - Privacy vs Fairness
    - Fairness vs Utility
- Accountability - there are Principles for Algorithmic Transparency and Accountability:
    - Need to be transparent and accountable when releasing software products/updates
- There are 4 main barriers to accountability:
    - The problem of many hands - Many people work on a single system. Makes it difficult to track responsibility.
    - The problem of bugs
    - Blaming the computer
    - Software ownership without liability
- There is a mismatch between automation and trust
- Consent and the Privacy Act - There are 4 key terms:
    - The individual is adequately informed before giving consent
    - The individual gives consent voluntarily
    - The consent is current and specific
    - The individual has the capacity to understand and communicate their consent

## Week 5

- Consequentialism is a theory that says whether something is good or bad depends on its outcomes
- Views of consequentialism:
    - Reductive view of consequentialism (misguided)
    - Eliminative view of consequentialism (wrong)
- Virtue signaling - pretending to be virtuous with an ulterior motive
- Virtues vs Vices
    - Virtue - a positive act
    - Vice - a negative act
    - These can be different for different people
- Virtue ethics brings the emotion into the center of the stories that it tells about the ways we should or should not act.
- It claims that the actions we take should be motivated by the right emotions to the right degree, and with this mindset we can see why virtue signaling is morally incorrect (actions motivated by the wrong emotions)
- Our emotions must be well-balanced for actions to be morally correct. Too much or too little can lead to acting viciously instead.
- Types of errors:
    - Type 1 errors - false positives
    - Type 2 errors - false negatives